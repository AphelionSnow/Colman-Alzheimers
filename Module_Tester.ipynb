{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d36ae9fc-4dfc-477a-a5cf-4180a1751757",
   "metadata": {},
   "outputs": [],
   "source": [
    "# requirements (install via pip):\n",
    "# faster-whisper==1.*  sounddevice webrtcvad numpy scipy torch\n",
    "# sentence-transformers wordfreq pronouncing nltk\n",
    "# (for Windows CPU-only whisper you may want: pip install torch --index-url https://download.pytorch.org/whl/cpu)\n",
    "\n",
    "import queue, threading, time, sys, re, json, os\n",
    "import numpy as np\n",
    "import sounddevice as sd\n",
    "import webrtcvad\n",
    "\n",
    "from faster_whisper import WhisperModel\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from wordfreq import zipf_frequency\n",
    "import pronouncing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cf98fbff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# Config\n",
    "# ---------------------------\n",
    "ASR_MODEL = \"medium\"        # try \"small\" or \"medium\" depending on your hardware\n",
    "DEVICE = \"cpu\"              # 'cuda' if you have a GPU; 'cpu' if not\n",
    "VAD_FRAME_MS = 20           # 10/20/30 ms frames allowed by webrtcvad\n",
    "SAMPLE_RATE = 16000\n",
    "CHANNELS = 1\n",
    "CONTEXT_SECONDS = 30        # window for suggestions\n",
    "TOP_K = 8\n",
    "PERSONAL_VOCAB_PATH = \"./personal_vocab.txt\"  # one word/phrase per line\n",
    "\n",
    "# Optional: letter / sound hint controls (connect to UI fields)\n",
    "HINT_FIRST_LETTER = None    # e.g., 'b'\n",
    "HINT_SYLLABLES = None       # e.g., 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c186ed3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# Audio + VAD\n",
    "# ---------------------------\n",
    "audio_q = queue.Queue()\n",
    "vad = webrtcvad.Vad(2)  # 0-3 (3 is most aggressive)\n",
    "\n",
    "def mic_callback(indata, frames, time_info, status):\n",
    "    if status:\n",
    "        print(status, file=sys.stderr)\n",
    "    # convert to 16-bit mono samples as bytes\n",
    "    pcm16 = (indata[:, 0] * 32767).astype(np.int16).tobytes()\n",
    "    audio_q.put(pcm16)\n",
    "\n",
    "def audio_stream():\n",
    "    with sd.InputStream(\n",
    "        samplerate=SAMPLE_RATE,\n",
    "        channels=CHANNELS,\n",
    "        dtype='float32',\n",
    "        blocksize=int(SAMPLE_RATE * VAD_FRAME_MS / 1000),\n",
    "        callback=mic_callback,\n",
    "    ):\n",
    "        while True:\n",
    "            time.sleep(0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bfb79c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# Rolling transcript store\n",
    "# ---------------------------\n",
    "class RollingTranscript:\n",
    "    def __init__(self, max_seconds=120):\n",
    "        self.segments = []  # list of (t, text)\n",
    "        self.max_seconds = max_seconds\n",
    "\n",
    "    def add(self, text):\n",
    "        t = time.time()\n",
    "        self.segments.append((t, text))\n",
    "        self.trim()\n",
    "\n",
    "    def trim(self):\n",
    "        cutoff = time.time() - self.max_seconds\n",
    "        self.segments = [(t, s) for (t, s) in self.segments if t >= cutoff]\n",
    "\n",
    "    def get_context(self, seconds):\n",
    "        cutoff = time.time() - seconds\n",
    "        text = \" \".join(s for (t, s) in self.segments if t >= cutoff)\n",
    "        return text.strip()\n",
    "\n",
    "transcript = RollingTranscript(max_seconds=300)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c8bde7f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# ASR worker (chunked)\n",
    "# ---------------------------\n",
    "def asr_worker():\n",
    "    model = WhisperModel(ASR_MODEL, device=DEVICE, compute_type=\"int8\")\n",
    "    buf = b\"\"\n",
    "    bytes_per_frame = int(SAMPLE_RATE * (VAD_FRAME_MS/1000)) * 2  # 16-bit mono\n",
    "    silence_bytes = b\"\\x00\" * bytes_per_frame\n",
    "    speech_chunk = b\"\"\n",
    "    last_speech_time = time.time()\n",
    "    speaking = False\n",
    "\n",
    "    while True:\n",
    "        try:\n",
    "            frame = audio_q.get(timeout=1.0)\n",
    "        except queue.Empty:\n",
    "            frame = silence_bytes\n",
    "\n",
    "        is_speech = vad.is_speech(frame, SAMPLE_RATE)\n",
    "\n",
    "        if is_speech:\n",
    "            speaking = True\n",
    "            last_speech_time = time.time()\n",
    "            speech_chunk += frame\n",
    "        else:\n",
    "            # if we were speaking and now silence, flush after short tail\n",
    "            if speaking and (time.time() - last_speech_time) > 0.35:\n",
    "                # decode this speech_chunk\n",
    "                audio_np = np.frombuffer(speech_chunk, dtype=np.int16).astype(np.float32) / 32768.0\n",
    "                segments, _ = model.transcribe(audio_np, language=\"en\", beam_size=1, vad_filter=False)\n",
    "                for seg in segments:\n",
    "                    piece = seg.text.strip()\n",
    "                    if piece:\n",
    "                        transcript.add(piece)\n",
    "                        print(\"[ASR]\", piece)\n",
    "                speech_chunk = b\"\"\n",
    "                speaking = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cc26fbe9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55dfad9fa5ed4d7aa9d8bf9e9607c0c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Joe\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Joe\\.cache\\huggingface\\hub\\models--sentence-transformers--all-MiniLM-L6-v2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0e7d4ae4e324914857d40b7023cfbd0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab3a11ddad0943ecb5d93f4494d3ae39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e223f39a6e2143198e51b0fa4bb29767",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a1082c94a68418fb166336c1c19c34e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "709045820ed142dd8354f0cfef75c006",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9103228fa4e34577b1895d6a9240be53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91b44394ac53494cbc3c30a61afc00cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54e1565d03ea440683ec3136ae20bbcb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86df1b51675841ddb3ee712016f249fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1947dde47b17490eafeb270b0b31fdb4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ---------------------------\n",
    "# Suggestion Engine\n",
    "# ---------------------------\n",
    "class SuggestionEngine:\n",
    "    def __init__(self, personal_vocab_path):\n",
    "        self.embedder = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "        self.personal_vocab = self._load_personal_vocab(personal_vocab_path)\n",
    "        self.core_vocab = self._load_core_vocab()\n",
    "        self.candidate_cache = {}  # word -> embedding\n",
    "\n",
    "        # build embeddings for personal vocab (do once)\n",
    "        _ = self._embed_list(self.personal_vocab)\n",
    "\n",
    "    def _load_personal_vocab(self, path):\n",
    "        if not os.path.exists(path):\n",
    "            return []\n",
    "        with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "            words = [w.strip() for w in f if w.strip()]\n",
    "        return list(dict.fromkeys(words))  # unique, preserve order\n",
    "\n",
    "    def _load_core_vocab(self, top_n=5000):\n",
    "        # you can replace this with a curated list; for demo, a small seed:\n",
    "        seed = [\n",
    "            \"appointment\",\"breakfast\",\"coffee\",\"doctor\",\"nurse\",\"medication\",\n",
    "            \"glasses\",\"television\",\"bathroom\",\"kitchen\",\"remote\",\"charger\",\n",
    "            \"daughter\",\"son\",\"grandson\",\"granddaughter\",\"neighbor\",\"friend\",\n",
    "            \"church\",\"pharmacy\",\"grocery\",\"walker\",\"wheelchair\",\"keys\",\"phone\",\n",
    "            \"wallet\",\"jacket\",\"mailbox\",\"bus\",\"taxi\",\"ride\",\"library\",\"park\"\n",
    "        ]\n",
    "        return seed\n",
    "\n",
    "    def _embed_list(self, words):\n",
    "        to_compute = [w for w in words if w not in self.candidate_cache]\n",
    "        if to_compute:\n",
    "            embs = self.embedder.encode(to_compute, normalize_embeddings=True)\n",
    "            for w, e in zip(to_compute, embs):\n",
    "                self.candidate_cache[w] = e\n",
    "        return np.array([self.candidate_cache[w] for w in words])\n",
    "\n",
    "    def _semantic_scores(self, context, candidates):\n",
    "        if not context.strip():\n",
    "            return np.zeros(len(candidates))\n",
    "        ctx_emb = self.embedder.encode([context], normalize_embeddings=True)[0]\n",
    "        cand_embs = self._embed_list(candidates)\n",
    "        return (cand_embs @ ctx_emb)  # cosine since normalized\n",
    "\n",
    "    def _freq_prior(self, word):\n",
    "        # Zipf 1-7; clamp and scale\n",
    "        return max(0.0, zipf_frequency(word, \"en\") - 3.0) / 4.0\n",
    "\n",
    "    def _phonetic_score(self, word, hint_first_letter=None, hint_syllables=None):\n",
    "        score = 0.0\n",
    "        if hint_first_letter:\n",
    "            score += 0.5 if word.lower().startswith(hint_first_letter.lower()) else 0.0\n",
    "        if hint_syllables is not None:\n",
    "            # crude syllable match via CMU dict:\n",
    "            phones = pronouncing.phones_for_word(word.lower())\n",
    "            if phones:\n",
    "                syls = [pronouncing.syllable_count(p) for p in phones]\n",
    "                if syls and min(abs(s - hint_syllables) for s in syls) == 0:\n",
    "                    score += 0.3\n",
    "        return score\n",
    "\n",
    "    def suggest(self, context_text, top_k=TOP_K, hint_first_letter=None, hint_syllables=None):\n",
    "        # build candidate pool\n",
    "        candidates = list(dict.fromkeys(self.personal_vocab + self.core_vocab))\n",
    "\n",
    "        # rank components\n",
    "        sem = self._semantic_scores(context_text, candidates)\n",
    "        pri = np.array([self._freq_prior(w) for w in candidates])\n",
    "        pho = np.array([self._phonetic_score(w, hint_first_letter, hint_syllables) for w in candidates])\n",
    "\n",
    "        # weighted blend (tune these)\n",
    "        scores = 0.70*sem + 0.20*pri + 0.10*pho\n",
    "\n",
    "        # sort & return\n",
    "        idx = np.argsort(-scores)\n",
    "        ranked = [(candidates[i], float(scores[i])) for i in idx[:top_k]]\n",
    "        return ranked\n",
    "\n",
    "engine = SuggestionEngine(PERSONAL_VOCAB_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f064a575",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# UI stub: button → suggestions\n",
    "# ---------------------------\n",
    "def on_button_press():\n",
    "    context = transcript.get_context(CONTEXT_SECONDS)\n",
    "    suggestions = engine.suggest(\n",
    "        context,\n",
    "        top_k=TOP_K,\n",
    "        hint_first_letter=HINT_FIRST_LETTER,\n",
    "        hint_syllables=HINT_SYLLABLES\n",
    "    )\n",
    "    print(\"\\n--- SUGGESTIONS ---\")\n",
    "    for w, s in suggestions:\n",
    "        print(f\"{w:20s}  {s:.3f}\")\n",
    "    print(\"-------------------\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e18cd0d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Live. Press Enter to show suggestions. Ctrl+C to exit.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1be8c301a01340cca967602957c5561a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d255dcaf711347dcb4346db576598095",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocabulary.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b56f95146cc9421ba2736fdbe6ebee23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Joe\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Joe\\.cache\\huggingface\\hub\\models--Systran--faster-whisper-medium. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45eafe2d2d56484680da05bf5288d390",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.bin:   0%|          | 0.00/1.53G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- SUGGESTIONS ---\n",
      "friend                0.119\n",
      "phone                 0.115\n",
      "son                   0.114\n",
      "park                  0.108\n",
      "church                0.108\n",
      "daughter              0.104\n",
      "doctor                0.095\n",
      "coffee                0.093\n",
      "-------------------\n",
      "\n",
      "\n",
      "--- SUGGESTIONS ---\n",
      "friend                0.119\n",
      "phone                 0.115\n",
      "son                   0.114\n",
      "park                  0.108\n",
      "church                0.108\n",
      "daughter              0.104\n",
      "doctor                0.095\n",
      "coffee                0.093\n",
      "-------------------\n",
      "\n",
      "\n",
      "--- SUGGESTIONS ---\n",
      "friend                0.119\n",
      "phone                 0.115\n",
      "son                   0.114\n",
      "park                  0.108\n",
      "church                0.108\n",
      "daughter              0.104\n",
      "doctor                0.095\n",
      "coffee                0.093\n",
      "-------------------\n",
      "\n",
      "\n",
      "--- SUGGESTIONS ---\n",
      "friend                0.119\n",
      "phone                 0.115\n",
      "son                   0.114\n",
      "park                  0.108\n",
      "church                0.108\n",
      "daughter              0.104\n",
      "doctor                0.095\n",
      "coffee                0.093\n",
      "-------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------\n",
    "# Launch threads\n",
    "# ---------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    t_audio = threading.Thread(target=audio_stream, daemon=True)\n",
    "    t_asr = threading.Thread(target=asr_worker, daemon=True)\n",
    "    t_audio.start()\n",
    "    t_asr.start()\n",
    "\n",
    "    print(\"Live. Press Enter to show suggestions. Ctrl+C to exit.\")\n",
    "    try:\n",
    "        while True:\n",
    "            input()  # simulate the big on-screen button\n",
    "            on_button_press()\n",
    "    except KeyboardInterrupt:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b483a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
